---
title: "p8105_hw3_os2424"
author: "Ou Sha"
date: "2023-10-14"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(ggplot2)
library(ggridges)
knitr::opts_chunk$set(echo = TRUE)
```

# Problem 1
```{r}
data("instacart")
```
The dataset has `r nrow(instacart)` observations of `r instacart |> select(user_id) |> distinct() |> count()` unique users. \
There are `r ncol(instacart)` columns:\
`order_id`: order identifier\
`product_id`: product identifier\
`add_to_cart_order`: order in which each product was added to cart\
`reordered`: 1 - reorder; 0 - otherwise\
`user_id`: customer identifier\
`eval_set`: which evaluation set this order belongs in\
`order_number`: the order sequence number for this user (1=first, n=nth)\
`order_dow`: the day of the week on which the order was placed\
`order_hour_of_day`: the hour of the day on which the order was placed\
`days_since_prior_order`: days since the last order, capped at 30, NA if order_number=1\
`product_name`: name of the product, such as spring water, asparagus etc.\
`aisle_id`: aisle identifier\
`department_id`: department identifier\
`aisle`: the name of the aisle, such as yogurt, cream etc\
`department`: the name of the department, such as produce, dairy eggs etc.

```{r}
# count aisles number
aisles <- instacart |>
  group_by(aisle)|>
  summarise(aisle_num = n())|>
  # order in ordered number to find most ordered aisles
  arrange(desc(aisle_num))
```
There are `r nrow(aisles)` aisles are there. The most ordered items are `r aisles|> head(1)`.\

```{r}
aisles_plot <- aisles |>
  # filter aisles w/ more than 10000 items
  filter(aisle_num > 10000)|>
  # make plot
  ggplot(aes(reorder(aisle, aisle_num), aisle_num))+
  coord_flip()+
  geom_point(stat = "identity") + 
  labs(title = "Number of items ordered in each aisle",
       x = "aisles",
       y = "number of order") +
  theme_minimal()
aisles_plot
ggsave("P1 Number of items ordered in each aisle.png", plot = last_plot())
```
```{r}
popular_aisle <- instacart|>
  # find items in these 3 aisles
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits"))|>
  group_by(aisle, product_name)|>
  summarise(order_num = n(), .groups = "keep")|>
  # order all the items in ordered number
  arrange(aisle, desc(order_num))|>
  group_by(aisle)|>
  # showing the three most popular
  slice_head(n=3)
popular_aisle
```

```{r}
mean_hr <- instacart|>
  # find items 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream"))|>
  group_by(product_name, order_dow)|>
  # find the mean hour of the day
  summarise(mean_hour = mean(order_hour_of_day), .groups = "keep")|>
  # make the day variable clear to read
  mutate(order_dow = case_when(order_dow == 0 ~ "Sunday", 
                               order_dow == 1 ~ "Monday",
                               order_dow == 2 ~ "Tuesday",
                               order_dow == 3 ~ "Wednesday",
                               order_dow == 4 ~ "Thursday",
                               order_dow == 5 ~ "Friday",
                               order_dow == 6 ~ "Saturday",))|>
  # make the 2*7 table
  spread(order_dow, mean_hour)
mean_hr
```

# Problem 2
```{r}
# import and clean data
data("brfss_smart2010")
brfss <- brfss_smart2010|>
  janitor::clean_names()|>
  # format the data to use appropriate variable names
  rename(state = locationabbr, state_county = locationdesc)|>
  # focus on the “Overall Health” topic
  filter(topic == "Overall Health")|>
  # include only responses from “Excellent” to “Poor”
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor"))|>
  # organize responses as a factor taking levels ordered from “Poor” to “Excellent”
  mutate(response = factor(response, levels=c("Poor", "Fair","Good","Very good","Excellent")))
```

```{r}
# find states observed at 7 or more locations 2002
brfss_2002 <- brfss|>
  # filter 2002
  filter(year == 2002)|>
  group_by(state)|>
  # count number of locations
  summarise(loc_num = length(unique(state_county)))|>
  # filer 7 or more locations
  filter(loc_num >= 7)
```
In 2002, states `r pull(brfss_2002, state)` were observed at 7 or more locations.
```{r}
# find states observed at 7 or more locations 2010
brfss_2010 <- brfss|>
  # filter 2002
  filter(year == 2010)|>
  group_by(state)|>
  # count number of locations
  summarise(loc_num = length(unique(state_county)))|>
  # filer 7 or more locations
  filter(loc_num >= 7)
```
In 2010, states `r pull(brfss_2010, state)` were observed at 7 or more locations.
```{r}
# Construct a dataset that is limited to Excellent responses
brfss_ex <- brfss|>
  # filter excellent response
  filter(response == "Excellent")|>
  group_by(year, state)|>
  # average data_value
  summarise(avg_value = mean(data_value, na.rm = TRUE), .groups = "keep")|>
  # make spaghetti plot
  ggplot(aes(x = year, y = avg_value, group = state, color = state)) +
  geom_line() +
  labs(title = "average value over time within a state",
       x = "year",
       y = "average data value") +
  theme_minimal()
brfss_ex
```
```{r}
# Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State
brfss_pl <- brfss|>
  # filter 2006 and 2010
  filter(year == 2006 | year == 2010)|>
  # filter ny state
  filter(state == "NY")|>
  # make plot 
  ggplot(aes(data_value, response))+
  facet_grid(~ year) +
  geom_density_ridges(scale=1)+
  labs(title = "distribution of data_value for responses (“Poor” to “Excellent”) in NY")+
  theme_minimal()
brfss_pl
```


# Problem 3
```{r}
# import data
covar <- read.csv("./data/nhanes_covar.csv",skip = 4,header = TRUE)
accel <- read.csv("./data/nhanes_accel.csv")
# clean data
covar <- covar|>
  # exclude participants less than 21
  filter(age>=21)|>
  # exclude participants with missing demographic data;
  na.omit()|>
  # encode data with reasonable variable classes 
  mutate(sex = if_else(sex==1, "male", "female"))|>
  mutate(education = case_when(education == 1 ~ "less than high school",
                               education == 2 ~ "high school equivalent",
                               education == 3 ~ "more than high school"))|>
  mutate(sex = factor(sex, levels= c("male", "female")))|>
  mutate(education = factor(education, levels = c("less than high school", "high school equivalent","more than high school")))
# merge data
merged <- inner_join(covar, accel, by = "SEQN")
merged <- merged|>
  janitor::clean_names()
# make it to a long format
merged_long <- pivot_longer(merged,
                            min1:min1440,
                            names_to = "time",
                            values_to = "mim")
```

```{r}
# make table for the number of men and women in each education category
edu <- merged|>
  group_by(sex, education)|>
  summarise(num = n(), .groups = "keep")|>
  spread(sex, num)
edu
```

```{r}
# create a visualization of the age distributions for men and women in each education category
age_edu <- merged|>
  ggplot(aes(x = age, y = education, fill = sex))+
  geom_density_ridges(scale = 0.5, alpha = 0.5)+
  labs(title = "age distributions for men and women in each education category")+
  theme_minimal()
age_edu
```

```{r}
total_act <- merged_long|>
  group_by(seqn, sex, age, education)|>
  # create a total activity variable for each participant
  summarise(total= sum(mim), .groups = "keep")|>
  # plot activities
  ggplot(aes(x = age, y = total, color = sex))+
  geom_point(alpha = 0.5)+
  facet_grid(~ education) +
  # add trend line
  geom_smooth(se = FALSE) + 
  labs(title = "age distributions for men and women in each education category",
       y = "total activity")+
  theme_minimal()
total_act
```

```{r}
# create a visualization of the age distributions for men and women in each education category
act_24 <- merged_long|>
  mutate(time = as.numeric(gsub("min", "", time)))|>
  arrange(time)|>
  ggplot(aes(x = time, y = mim, color = sex))+
  geom_point(alpha = 0.5)+
  facet_grid(~ education) +
  # add trend line
  geom_smooth(se = FALSE) + 
  labs(title = "24-hour activity time courses for each education level",
       y = "total activity")+
  theme_minimal()
act_24
```
